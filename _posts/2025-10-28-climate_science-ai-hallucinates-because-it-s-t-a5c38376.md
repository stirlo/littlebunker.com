---
layout: feed_item
title: "AI hallucinates because it’s trained to fake answers it doesn’t know"
date: 2025-10-28 22:25:09 +0000
categories: [climate_science]
tags: []
keywords: ['because', 'trained', 'hallucinates']
description: "Teaching chatbots to say “I don’t know” could curb hallucinations"
external_url: https://www.science.org/content/article/ai-hallucinates-because-it-s-trained-fake-answers-it-doesn-t-know
is_feed: true
source_feed: "Latest News from Science Magazine"
feed_category: "climate_science"
---

Teaching chatbots to say “I don’t know” could curb hallucinations. It could also break AI’s business model

[Read original article](https://www.science.org/content/article/ai-hallucinates-because-it-s-trained-fake-answers-it-doesn-t-know)
